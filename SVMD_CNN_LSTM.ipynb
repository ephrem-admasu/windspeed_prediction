{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from math import *\n",
    "#from sklearn.models import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "RANDOM_SEED = 42\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = ['#01BEFE', '#FFDD00', '#FF7D00', '#FF006D', '#ADFF02', '#8F00FF']\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 8, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### April Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inputs/SVMD_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv('inputs/DS1_1440.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imfs = np.array([df[col].values for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = orig_df.wind_speed.values - imfs.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_decomp = np.concatenate([imfs, error.reshape(1, -1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1440)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_decomp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CNNLSTMForecast, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #cnn takes input of shape (batch_size, channels, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn(x)\n",
    "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import create_features, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global tot_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, train_loader, optimizer, criterion):\n",
    "        \n",
    "    running_loss = .0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "\n",
    "    \n",
    "    # print(f'train_loss {train_loss}')\n",
    "    \n",
    "def Valid(model, valid_loader, optimizer, criterion):\n",
    "    running_loss = .0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predctions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 #number of features\n",
    "hidden_size = 200 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "seq_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tot_decomp)):\n",
    "\n",
    "    model = CNNLSTMForecast(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_len = int(.6*tot_decomp.shape[1])\n",
    "    train_data, val_data, test_data = split_data(tot_decomp[i, :], train_len)\n",
    "    train_data = np.float32(train_data)\n",
    "    val_data = np.float32(val_data)\n",
    "    test_data = np.float32(test_data)\n",
    "\n",
    "    xtrain, ytrain = create_features(train_data, window_size)\n",
    "    xval, yval = create_features(val_data, window_size)\n",
    "    xtest, ytest = create_features(test_data, window_size)\n",
    "\n",
    "    train = WindDataset(xtrain.reshape(xtrain.shape[0], 1, xtrain.shape[1]), ytrain)\n",
    "    valid = WindDataset(xval.reshape(xval.shape[0], 1, xval.shape[1]), yval)\n",
    "    test = WindDataset(xtest.reshape(xtest.shape[0], 1, xtest.shape[1]), ytest)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False)\n",
    "    valid_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "        Train(model, train_loader, optimizer, criterion)\n",
    "        Valid(model, valid_loader, optimizer, criterion)\n",
    "        gc.collect()\n",
    "\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model.forward(inputs)\n",
    "                \n",
    "            predictions.append(preds.item())\n",
    "    all_predctions.append(predictions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079519441232528"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, test = split_data(orig_df.wind_speed.values, train_len)\n",
    "_, ytes = create_features(test, window_size)\n",
    "\n",
    "all_preds = np.array([pred for pred in all_predctions]).sum(axis=0)\n",
    "mse(all_preds, ytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.01087415, 11.38266122, 11.8337919 , 11.39067348, 10.86771159,\n",
       "       10.46304697, 10.31153654, 10.70922196, 10.03271736, 10.46446239,\n",
       "       10.4551545 ,  9.78595465,  9.54066101,  9.1264707 ,  9.05753418,\n",
       "        8.85437032,  8.73123191,  8.88283913,  8.48610983,  8.01797293,\n",
       "        7.63595568,  7.70193258,  7.93584391,  7.93049605,  7.95274138,\n",
       "        8.26728433,  7.95152839,  8.20119161,  8.19619446,  8.08709554,\n",
       "        8.10952662,  8.84816869,  8.72161406,  8.59169206,  9.69968739,\n",
       "        9.97348009,  9.74186297,  9.2085916 ,  9.56506838, 10.05344355,\n",
       "        9.98819032,  9.56720677,  9.4275665 ,  9.91812546,  9.94274881,\n",
       "        9.92414685, 10.18293482, 10.71238156, 11.02542123, 10.84765381,\n",
       "       10.1239273 , 10.54459451, 10.53103498, 10.41320439, 10.51785363,\n",
       "       10.30417887, 10.48530903, 10.20941931, 10.16596554, 10.70308118,\n",
       "        9.43420567,  9.24152778,  9.36340097,  9.66387448,  9.48352171,\n",
       "        9.54472854,  9.34079918,  9.24320376,  9.22756653,  9.71064296,\n",
       "        9.75814189, 10.08589382,  9.7099735 ,  9.62163916,  9.49650069,\n",
       "        9.86994409,  9.89404394,  9.63149454,  9.08675249,  8.56675537,\n",
       "        9.17242489,  8.63474176,  8.66285279,  7.67350306,  4.12621742,\n",
       "        7.00356947,  6.47671734,  7.30000857,  6.06190813,  6.90629971,\n",
       "        6.95974296,  7.36894038,  6.91639438,  6.74536605,  6.50687028,\n",
       "        6.3308806 ,  6.14451213,  6.1530835 ,  6.1591197 ,  6.39473824,\n",
       "        6.4647325 ,  6.50099128,  6.56272596,  6.47087306,  7.28397263,\n",
       "        7.39945132,  7.59177033,  8.04911326,  7.69907992,  8.5082736 ,\n",
       "        7.10020487,  7.16756818,  7.86064968,  7.31940456,  7.38447931,\n",
       "        7.21360821,  7.4515067 ,  7.64635937,  7.76697206,  8.06846577,\n",
       "        8.67206538,  7.66723584,  7.91787063,  7.9681816 ,  8.129248  ,\n",
       "        8.96994314,  8.35282407,  8.35502062,  8.59661189,  8.53691469,\n",
       "        9.01140135,  9.09291761,  9.88455625,  9.83085348, 10.2905588 ,\n",
       "       10.84441018,  7.95176673,  6.8766461 ,  7.42096966,  8.79585633,\n",
       "        9.27465756,  8.76818829,  8.86603045,  9.41264838,  9.19916737,\n",
       "        8.86278167,  9.45467234,  9.78343934,  9.78955044,  9.60353051,\n",
       "       10.34751135, 10.44813478, 10.5125016 , 11.02959245, 11.200957  ,\n",
       "        9.96602628,  9.28876838,  8.81808385,  9.52973235,  9.55440465,\n",
       "        9.28476176,  9.22345851,  8.80248225,  8.00857335,  7.73849701,\n",
       "        6.92846721,  7.2808026 ,  7.69582213,  6.91413762,  7.40762271,\n",
       "        7.02133442,  6.56436577,  6.77482904,  7.12062883,  7.40020087,\n",
       "        7.85285502,  7.87219808,  8.36436502,  8.53575944,  9.00020505,\n",
       "        9.10918269,  9.7798726 ,  9.83355539,  9.10915728,  8.41750317,\n",
       "        8.82202569,  8.75917316,  8.57166059,  8.57083811,  8.84010397,\n",
       "        8.49421822,  9.25523642,  9.77000794,  9.6616229 ,  9.61036571,\n",
       "       10.21987003, 10.69092917, 10.25868856, 11.11653291, 10.41266374,\n",
       "       10.48812698,  9.99514278,  9.25449754,  8.28778386,  8.68586241,\n",
       "        8.94926528,  8.48028107,  7.93940231,  8.1316736 ,  7.70052432,\n",
       "        6.73650786,  7.11116015,  6.36462124,  6.4536447 ,  7.81260683,\n",
       "        6.86149317,  6.91107211,  7.85433454,  8.01551829,  7.68944292,\n",
       "        7.60219068,  8.66100048,  8.89944906,  8.46561801,  7.81578679,\n",
       "        7.7362739 ,  8.64094634,  7.89371963,  8.21139882,  7.87623318,\n",
       "        8.46395372,  8.39781587,  7.9573566 ,  7.96954843,  9.18513936,\n",
       "        9.52676033,  9.84938459, 11.06611274, 11.99419267, 12.09069946,\n",
       "       11.53064874,  9.1243854 ,  8.93208931,  9.84251224,  9.65854697,\n",
       "       10.60324273,  9.97929756,  9.95590466, 10.06523121, 10.71654783,\n",
       "        9.21524073,  9.80527851,  9.38590971,  8.6779568 ,  8.55453813,\n",
       "        7.91617258,  7.44823483,  6.93006771,  6.88448324,  6.20970766,\n",
       "        6.40837232,  6.2464864 ,  6.56082202,  6.83858971,  7.21751202,\n",
       "        7.36246012,  7.64298645,  7.58117445,  7.96160483,  8.0258676 ,\n",
       "        7.95114048,  8.2845486 ,  8.35403672,  8.68702914,  8.83039312,\n",
       "        9.30181429,  9.25547601,  8.71171375,  9.24993095,  9.13647899,\n",
       "        9.54047817,  9.59743106,  8.67913958])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('svmd_cnn_lstm_1', 'ab')\n",
    "pickle.dump(all_preds, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inputs/SVMD_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv('inputs/DS2_1448.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imfs = np.array([df[col].values for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = orig_df.wind_speed.values - imfs.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_decomp = np.concatenate([imfs, error.reshape(1, -1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1488)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_decomp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, train_loader, optimizer, criterion):\n",
    "        \n",
    "    running_loss = .0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "\n",
    "    \n",
    "    # print(f'train_loss {train_loss}')\n",
    "    \n",
    "def Valid(model, valid_loader, optimizer, criterion):\n",
    "    running_loss = .0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predctions_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 #number of features\n",
    "hidden_size = 200 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "seq_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tot_decomp)):\n",
    "\n",
    "    model = CNNLSTMForecast(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_len = int(.6*tot_decomp.shape[1])\n",
    "    train_data, val_data, test_data = split_data(tot_decomp[i, :], train_len)\n",
    "    train_data = np.float32(train_data)\n",
    "    val_data = np.float32(val_data)\n",
    "    test_data = np.float32(test_data)\n",
    "\n",
    "    xtrain, ytrain = create_features(train_data, window_size)\n",
    "    xval, yval = create_features(val_data, window_size)\n",
    "    xtest, ytest = create_features(test_data, window_size)\n",
    "\n",
    "    train = WindDataset(xtrain.reshape(xtrain.shape[0], 1, xtrain.shape[1]), ytrain)\n",
    "    valid = WindDataset(xval.reshape(xval.shape[0], 1, xval.shape[1]), yval)\n",
    "    test = WindDataset(xtest.reshape(xtest.shape[0], 1, xtest.shape[1]), ytest)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False)\n",
    "    valid_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "        Train(model, train_loader, optimizer, criterion)\n",
    "        Valid(model, valid_loader, optimizer, criterion)\n",
    "        gc.collect()\n",
    "\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model.forward(inputs)\n",
    "                \n",
    "            predictions.append(preds.item())\n",
    "    all_predctions_2.append(predictions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076012489401859"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, test = split_data(orig_df.wind_speed.values, train_len)\n",
    "_, ytes = create_features(test, window_size)\n",
    "\n",
    "all_preds_2 = np.array([pred for pred in all_predctions_2]).sum(axis=0)\n",
    "mse(all_preds_2, ytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('svmd_cnnlstm_2', 'ab')\n",
    "pickle.dump(all_preds_2, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
